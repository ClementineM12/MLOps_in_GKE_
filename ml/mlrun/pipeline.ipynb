{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Cancer Pipeline\n",
    "\n",
    "This pipeline performs the following steps:\n",
    "1. **Fetch Dataset:** Check if the dataset exists in MinIO (or download it from Kaggle if not), then upload it.\n",
    "2. **Process Data:** Load the metadata CSV, merge image paths, and perform some plotting.\n",
    "3. **Feature Engineering:** Perform feature engineering on the processed metadata.\n",
    "4. **Train Random Forest Model:** Train a Random Forest model on the engineered dataset.\n",
    "5. **Train CNN Model:** Train a CNN on a sample of the engineered dataset.\n",
    "\n",
    "Below is the complete pipeline implementation using MLRun in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install minio\n",
    "!pip install mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Project\n",
    "Create a project using mlrun.get_or_create_project (make sure to load it in case it already exists), creating the paths where we'll store the project's artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mlrun\n",
    "import os\n",
    "\n",
    "# Set our project's name:\n",
    "project_name = \"skin-cancer-detection\"\n",
    "project_dir = os.path.abspath('./')\n",
    "\n",
    "# Create the project:\n",
    "project = mlrun.get_or_create_project(project_name, project_dir, user_project=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A project in MLRun is based on the MLRun Functions it can run. In this notebook we will see two ways to create a MLRun Function:\n",
    "\n",
    "* `mlrun.code_to_function`: Create our own MLRun Function from code (will be used for training and evaluation in section 4).\n",
    "* `mlrun.import_function`: Import from [MLRun's functions marketplace](https://www.mlrun.org/hub/) - a [functions hub](https://docs.mlrun.org/en/v1.1.2/runtimes/load-from-marketplace.html) intended to be a centralized location for open source contributions of function components (will be used for downloading the data in section 2).\n",
    "\n",
    "Before we continue, **please select the desired framework** (comment and uncomment the below lines as needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "framework = \"tf-keras\"\n",
    "# framework = \"pytorch\"\n",
    "\n",
    "# If you wish to train on gpu, set this variable to 'True', otherwise 'False':\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build project images\n",
    "Building the images to satisfy the requirements of the project, according to the selection above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlrun\n",
    "\n",
    "# Define your framework and GPU usage.\n",
    "# (Assume these variables are defined elsewhere in your notebook or pipeline.)\n",
    "# framework = 'tf-keras'  # or 'torch'\n",
    "# use_gpu = True or False\n",
    "\n",
    "\n",
    "if framework == 'tf-keras':\n",
    "    commands = [\n",
    "        'pip install kaggle==1.5.12',\n",
    "        'pip install minio==7.1.5',\n",
    "        'pip install tensorflow~=2.9.0',\n",
    "        'pip install horovod==0.25.0',\n",
    "        'pip install pandas==1.4.0',\n",
    "        'pip install matplotlib==3.5.1',\n",
    "        'pip install seaborn==0.11.2',\n",
    "        'pip install scikit-learn==1.1.1',\n",
    "        'pip install opencv-python==4.5.5.64',\n",
    "    ]\n",
    "    builder_env = {\n",
    "        'HOROVOD_WITH_MPI': '1',\n",
    "        'HOROVOD_WITH_TENSORFLOW': '1'\n",
    "    }\n",
    "elif framework == 'torch':\n",
    "    commands = [\n",
    "        'pip install torch==1.13.0+cpu',\n",
    "        'pip install torchvision==0.14.0+cpu -f https://download.pytorch.org/whl/torch_stable.html',\n",
    "        'pip install tensorboard==2.5.0',\n",
    "        'pip install horovod==0.25.0',\n",
    "        'pip install onnx~=1.15.0',\n",
    "        'pip install pandas==1.4.0',\n",
    "        'pip install matplotlib==3.5.1',\n",
    "        'pip install seaborn==0.11.2',\n",
    "        'pip install scikit-learn==1.1.1',\n",
    "        'pip install opencv-python==4.5.5.64',\n",
    "        'pip install Pillow==9.0.1',\n",
    "        'pip install numpy==1.21.5',\n",
    "    ]\n",
    "    builder_env = {\n",
    "        'HOROVOD_WITH_MPI': '1',\n",
    "        'HOROVOD_WITH_PYTORCH': '1'\n",
    "    }\n",
    "\n",
    "# If not using GPU, prepend an apt update/install command and set the proper env flag.\n",
    "if not use_gpu:\n",
    "    apt_cmd = [\n",
    "        \"apt update -qqq --fix-missing && apt upgrade -y && apt install -y build-essential cmake gcc \",\n",
    "        \"&& apt clean && rm -rf /var/lib/apt/lists/*\",\n",
    "    ]\n",
    "    commands = apt_cmd + commands\n",
    "    builder_env['HOROVOD_WITHOUT_GLOO'] = '1'\n",
    "else:\n",
    "    commands = commands\n",
    "\n",
    "# Build the image.\n",
    "# The image tag will be constructed as: \".cancer-detection-<framework>\".\n",
    "# The base image is set to \"mlrun/mlrun-gpu\" if using GPU, else \"mlrun/mlrun\".\n",
    "project.build_image(\n",
    "    image=f\".cancer-detection-{framework}\",\n",
    "    base_image='mlrun/mlrun-gpu' if use_gpu else 'mlrun/mlrun',\n",
    "    commands=commands,\n",
    "    builder_env=builder_env,\n",
    "    extra_args=\"--skip-tls-verify\",\n",
    "    overwrite_build_params=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "project.build_image(\n",
    "    image=\".load-data\",\n",
    "    base_image='mlrun/mlrun',\n",
    "    commands=[\n",
    "        'pip install kagglehub',\n",
    "        'pip install minio',\n",
    "    ],\n",
    "    extra_args=\"--skip-tls-verify\",\n",
    "    overwrite_build_params=True\n",
    ")\n",
    "\n",
    "project.build_image(\n",
    "    image=\".process-data\",\n",
    "    base_image='mlrun/mlrun',\n",
    "    commands=[\n",
    "        'pip install minio',\n",
    "        'pip install pandas',\n",
    "        'pip install matplotlib==3.5.3',   # Pin matplotlib to a compatible version\n",
    "        'pip install seaborn',      \n",
    "        'pip install scikit-learn',\n",
    "        'pip install opencv-python-headless',\n",
    "        'pip install Pillow',\n",
    "        'pip install numpy',\n",
    "    ],\n",
    "    extra_args=\"--skip-tls-verify\",\n",
    "    overwrite_build_params=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the MLRun Function & Run\n",
    "We will use MLRun's `mlrun.code_to_function` to create a MLRun Function from our code in the above mentioned python file. \n",
    "\n",
    "We wish to run the load first as a Job, so we will set the kind parameter to \"job\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "metadata_filename = \"HAM10000_metadata.csv\" \n",
    "source_bucket = \"data\" \n",
    "processed_bucket = \"processed-data\"\n",
    "processed_metadata_filename = \"processed_metadata.pkl\"\n",
    "images_dir = \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create the function parsing the given file code using 'code_to_function':\n",
    "process_function = mlrun.code_to_function(\n",
    "    filename=\"functions/process.py\",\n",
    "    name=\"process-data\",\n",
    "    kind=\"job\",\n",
    "    image='.process-data'\n",
    ")\n",
    "\n",
    "process_function.with_requests(mem=\"12G\")  # lower bound\n",
    "process_function.with_limits(mem=\"12G\")  # upper bound\n",
    "\n",
    "process_run = process_function.run(\n",
    "    name=\"Preprocess data\",\n",
    "    handler=\"process_metadata\",\n",
    "    params={\n",
    "        \"metadata_filename\": metadata_filename,\n",
    "        \"source_bucket\": source_bucket, \n",
    "        \"processed_bucket\": processed_bucket,\n",
    "        \"images_dir\": images_dir,\n",
    "        \"processed_metadata_filename\": processed_metadata_filename,\n",
    "    },\n",
    "    local=False\n",
    ")\n",
    "\n",
    "# Wait for complition and show the results. \n",
    "process_run.wait_for_completion()\n",
    "process_run.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create the function that will create segmented images\n",
    "create_segmented_function = mlrun.code_to_function(\n",
    "    filename=\"functions/process.py\",\n",
    "    name=\"process-images\",\n",
    "    kind=\"job\",\n",
    "    image='.process-data'\n",
    ")\n",
    "\n",
    "# process_function.with_requests(mem=\"1G\", cpu=1)  # lower bound\n",
    "# process_function.with_limits(mem=\"2G\", cpu=2)  # upper bound\n",
    "\n",
    "create_segmented_run = create_segmented_function.run(\n",
    "    name=\"Preprocess images\",\n",
    "    handler=\"create_segmented_images\",\n",
    "    params={\n",
    "        \"processed_bucket\": processed_bucket,\n",
    "        \"processed_metadata_filename\": processed_metadata_filename\n",
    "        \"n_samples\": 2000,\n",
    "    },\n",
    "    local=False,\n",
    "    watch=True,  # <- Turn on the logs.\n",
    ")\n",
    "\n",
    "# Wait for complition and show the results. \n",
    "create_segmented_run.wait_for_completion()\n",
    "create_segmented_run.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
